% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/idf_functions.R
\name{fit_egpd_idf_data_driven}
\alias{fit_egpd_idf_data_driven}
\title{function for fitting of data-driven IDF models}
\usage{
fit_egpd_idf_data_driven(
  station_data,
  durations,
  declustering_duration,
  initial_params,
  censored,
  fitting_method = "mle",
  init_time_step = 1,
  use_mle_init = F,
  optim_algo = "Nelder-Mead"
)
}
\arguments{
\item{station_data}{data_frame of observation for a station (nobs x aggregation duration)}

\item{durations}{a (vector) of durations (same length as ncol of station_data)}

\item{declustering_duration}{a vector same length as \code{duration} .Whether the data should be temporally declustered, if yes the time step for each duration, or a vector of 1 otherwise}

\item{initial_params}{an object returned by \code{egpd_idf_init}.}

\item{censored}{a scalar or vector of \code{length(durations)}, for the left censoring to be applied to data of each duration. If a scalar is given, it will be divided by \code{durations}}

\item{fitting_method}{either \code{"mle"} for maximum likelihood or \code{"pwm"} for probability weighted momoments. Defaults to \code{"mle"}}

\item{init_time_step}{a scalar, eg 1 or 2. The time step to start declustering the data. eg, for hourly data, if  \code{declustering =3} and  \code{init_time_step = 2}, then the 2nd hour will be selected, and then a sequence is applied}

\item{use_mle_init}{logical, defaults  to \code{FALSE}, if yes, an iterative pairwise likelohoof fitting is done. See ...}

\item{optim_algo}{the \code{optim} algtorthm to use. defaults to \code{"Nelder-Mead" }}
}
\value{
# A list:

   fits: egdp parameters fit for each duration seperately
   optim details, to check convergence
}
\description{
a 10 parameter IDF model in which the form of the EGPD parameter dependence is emperically
 determined from the data it self  For details, see Haruna et al 2023
}
\details{
to be added
}
\examples{
 ## load the data
 data("precipdata")

 ## Here the resolution of the data is 'hours', we want to aggeregate the data up to 72 hours
 ## specify the aggregation durations

 durations =  c(1,2, 3,  6,  10, 12,  16, 18,  24, 48, 72)

 ## get the aggrageted data for each of the
station_data= aggregate_data(sample_data = precipdata, st_code = "SCH",
 durations = durations)
\dontrun{
 ## get initial values

 initial_params = egpd_idf_init(station_data = station_data,
             durations = durations, fitting_method = "mle",
               declustering_duration =  c(1,2,3,6,10,12, 16,18, 24, 48, 72),
               auto_fit = T, nrmse_tol = 0.1,use_r_optim = T, nrsme_quantile = 0)
 ## fit the data driven IDF
 fitted_idf = fit_egpd_idf_data_driven(station_data = station_data, durations = durations,
             declustering_duration = c(1,2, 3,  6,  10, 12,  16, 18,  24, 48, 72),
             fitting_method = 'mle',  initial_params = initial_params,
              optim_algo = "BFGS")

 #check 'optim' params, for convergencem etc
 fitted_idf$fitted_params

 #parameters of the IDF
 fitted_idf$fitted_params$par

 # fitted egpd parameters for the given durations
 kappa_fit =  fitted_idf$kappa_param
 sigma_fit = fitted_idf$scale_param
 xi_fit = fitted_idf$shape_param

 #compute nrmse to check quality of fit
 nrmse_d = compute_nrsme(station_data, c(1,2,3,6,10,12, 16,18, 24, 48, 72),
  kappa_fit, sigma_fit, xi_fit, init_time_step = 1, q = 0)
 nrmse_d

# Plot the IDF curves
plot_egpdidf_curves(station_data = station_data,  kappa_fit = kappa_fit,
sigma_fit = sigma_fit, xi_fit = xi_fit, durations,
 declustering_duration=c(1,2,3,6,10,12, 16,18, 24, 48, 72), npy = 92, init_time_step=1 )
 }
}
